"""
Rich console renderer (Layer 3).

Outputs formatted text with colors, panels, and syntax highlighting
using the Rich library.
"""

import typing as _typing

import rich.console as _rich_console
import rich.live as _rich_live
import rich.markdown as _rich_markdown
import rich.panel as _rich_panel
import rich.prompt as _rich_prompt
import rich.syntax as _rich_syntax
import rich.text as _rich_text

import brynhild.ui.base as base
import brynhild.ui.icons as icons


class RichConsoleRenderer(base.Renderer):
    """
    Rich console renderer with colors and formatting.

    Uses the Rich library for beautiful terminal output including:
    - Colored text and panels
    - Markdown rendering
    - Syntax highlighting
    - Live streaming updates
    """

    def __init__(
        self,
        console: _rich_console.Console | None = None,
        *,
        force_terminal: bool | None = None,
        no_color: bool = False,
        show_thinking: bool = False,
    ) -> None:
        """
        Initialize the Rich renderer.

        Args:
            console: Rich Console instance (created if not provided).
            force_terminal: Force terminal mode even if not detected.
            no_color: Disable all colors.
            show_thinking: If True, display full thinking/reasoning content.
        """
        self._console = console or _rich_console.Console(
            force_terminal=force_terminal,
            no_color=no_color,
        )
        self._streaming = False
        self._stream_content = ""
        self._live: _rich_live.Live | None = None
        self._show_thinking = show_thinking

        # Thinking streaming state
        self._thinking_live: _rich_live.Live | None = None
        self._thinking_content = ""

        # Token tracking for panel footers
        self._cumulative_input_tokens = 0
        self._cumulative_output_tokens = 0

    def update_token_counts(self, input_tokens: int, output_tokens: int) -> None:
        """
        Set cumulative token counts.

        Called after each API call to track context window usage.
        Values are cumulative totals, not deltas.

        Args:
            input_tokens: Cumulative tokens sent to the model (context size).
            output_tokens: Cumulative tokens generated by the model.
        """
        self._cumulative_input_tokens = input_tokens
        self._cumulative_output_tokens = output_tokens

    def _token_footer(self) -> str:
        """Generate a token count footer string."""
        if self._cumulative_input_tokens == 0 and self._cumulative_output_tokens == 0:
            return ""
        return (
            f"[dim]context: {self._cumulative_input_tokens:,} tokens | "
            f"generated: {self._cumulative_output_tokens:,}[/dim]"
        )

    def show_thinking(self, thinking: str) -> None:
        """
        Display thinking/reasoning content in a visually distinct panel.

        Only called when show_thinking=True to print the final persistent panel.

        Args:
            thinking: The thinking content to display.
        """
        if not thinking.strip():
            return

        # Truncate very long thinking for display (but full version is logged)
        display_thinking = thinking
        if len(display_thinking) > 5000:
            display_thinking = display_thinking[:4997] + "..."

        self._console.print(
            _rich_panel.Panel(
                _rich_text.Text(display_thinking, style="italic dim"),
                title="[bold magenta]üí≠ Thinking[/bold magenta]",
                subtitle=self._token_footer() or None,
                border_style="magenta",
                style="dim",
            )
        )

    def start_thinking_stream(self) -> None:
        """Start live streaming display for thinking content."""
        self._thinking_content = ""
        self._thinking_live = _rich_live.Live(
            _rich_panel.Panel(
                _rich_text.Text("...", style="italic dim"),
                title="[bold magenta]üí≠ Thinking[/bold magenta]",
                border_style="magenta",
                style="dim",
            ),
            console=self._console,
            refresh_per_second=10,
            transient=True,  # Vanishes when stopped
        )
        self._thinking_live.start()

    def update_thinking_stream(self, text: str) -> None:
        """
        Update the thinking stream with new content.

        Args:
            text: New thinking text to append.
        """
        self._thinking_content += text
        if self._thinking_live:
            # Truncate for display if very long
            display = self._thinking_content
            if len(display) > 5000:
                display = display[:4997] + "..."
            self._thinking_live.update(
                _rich_panel.Panel(
                    _rich_text.Text(display, style="italic dim"),
                    title="[bold magenta]üí≠ Thinking[/bold magenta]",
                    border_style="magenta",
                    style="dim",
                )
            )

    def end_thinking_stream(self, *, persist: bool = False) -> None:
        """
        End thinking stream display.

        Args:
            persist: If True, print the final panel permanently.
                     If False, just let it vanish (transient).
        """
        if self._thinking_live:
            self._thinking_live.stop()
            self._thinking_live = None

            if persist and self._thinking_content.strip():
                # Print permanent panel
                self.show_thinking(self._thinking_content)

        self._thinking_content = ""

    def show_session_banner(
        self,
        *,
        model: str,
        provider: str,
        profile: str | None = None,
        session: str | None = None,
    ) -> None:
        """
        Display session info banner at the start of a conversation.

        Args:
            model: Model name/identifier.
            provider: Provider name (openrouter, ollama, etc).
            profile: Profile name if using one, or None for default.
            session: Session name if resuming, or None/new for new session.
        """
        # Build info parts
        parts = [f"[bold]{model}[/bold] [dim]({provider})[/dim]"]

        if profile:
            parts.append(f"Profile: [cyan]{profile}[/cyan]")
        else:
            parts.append("Profile: [dim]default[/dim]")

        if session and session != "new":
            parts.append(f"Session: [yellow]{session}[/yellow]")
        else:
            parts.append("Session: [dim]new[/dim]")

        content = " ‚îÇ ".join(parts)

        self._console.print(
            _rich_panel.Panel(
                content,
                border_style="dim",
                padding=(0, 1),
            )
        )

    def show_user_message(self, content: str) -> None:
        """Display a user message with formatting."""
        self._console.print(
            _rich_panel.Panel(
                content,
                title="[bold blue]You[/bold blue]",
                subtitle=self._token_footer() or None,
                border_style="blue",
            )
        )

    def show_assistant_text(self, text: str, *, streaming: bool = False) -> None:
        """Display assistant text response."""
        if streaming:
            self._stream_content += text
            # Lazily create Live display on first text
            if not self._live:
                self._live = _rich_live.Live(
                    _rich_panel.Panel(
                        _rich_markdown.Markdown(self._stream_content),
                        title="[bold green]Assistant[/bold green]",
                        border_style="green",
                    ),
                    console=self._console,
                    refresh_per_second=10,
                    transient=True,
                )
                self._live.start()
            else:
                # Update existing Live display
                self._live.update(
                    _rich_panel.Panel(
                        _rich_markdown.Markdown(self._stream_content),
                        title="[bold green]Assistant[/bold green]",
                        subtitle=self._token_footer() or None,
                        border_style="green",
                    )
                )
        else:
            if not self._streaming:
                # Complete message (non-streaming)
                self._console.print(
                    _rich_panel.Panel(
                        _rich_markdown.Markdown(text),
                        title="[bold green]Assistant[/bold green]",
                        subtitle=self._token_footer() or None,
                        border_style="green",
                    )
                )

    def show_tool_call(self, tool_call: base.ToolCallDisplay) -> None:
        """Display that a tool is being called."""
        # Format the input as a simple key-value display
        input_lines: list[str] = []
        for key, value in tool_call.tool_input.items():
            value_str = str(value)
            if len(value_str) > 100:
                value_str = value_str[:97] + "..."
            input_lines.append(f"[dim]{key}:[/dim] {value_str}")

        content = "\n".join(input_lines) if input_lines else "[dim]No parameters[/dim]"

        # Use different styling for recovered vs native tool calls
        if tool_call.is_recovered:
            # Prominent warning banner for recovered calls
            self._console.print(
                "[bold #ff8c00 on #3d2600]"
                f" {icons.icon_warning()}RECOVERED FROM MODEL THINKING "
                "[/bold #ff8c00 on #3d2600]"
            )
            self._console.print(
                "[dim #ff8c00]"
                "   Model emitted JSON in thinking instead of proper tool call"
                "[/dim #ff8c00]"
            )

            # Orange border with warning icon
            title = f"[bold #ff8c00]{icons.icon_warning()}{tool_call.tool_name}[/bold #ff8c00]"
            subtitle = "[dim #ff8c00](recovered from model thinking)[/dim #ff8c00]"
            border_style = "#ff8c00"  # Orange
        else:
            # Yellow border and "‚ö°" for native calls
            title = f"[bold yellow]{icons.icon_bolt()}{tool_call.tool_name}[/bold yellow]"
            subtitle = None
            border_style = "yellow"

        # Combine recovery subtitle with token footer
        footer_parts = []
        if subtitle:
            footer_parts.append(subtitle)
        token_footer = self._token_footer()
        if token_footer:
            footer_parts.append(token_footer)
        combined_subtitle = " | ".join(footer_parts) if footer_parts else None

        self._console.print(
            _rich_panel.Panel(
                content,
                title=title,
                subtitle=combined_subtitle,
                border_style=border_style,
            )
        )

    def show_tool_result(self, result: base.ToolResultDisplay) -> None:
        """Display the result of a tool call."""
        token_subtitle = self._token_footer() or None

        if result.result.success:
            output = result.result.output.strip()
            if len(output) > 2000:
                output = output[:1997] + "..."

            # Try to detect and syntax-highlight the output
            # For now, just use plain text - could add syntax detection later
            content: _rich_text.Text | _rich_syntax.Syntax | str = (
                output or "[dim]No output[/dim]"
            )

            self._console.print(
                _rich_panel.Panel(
                    content,
                    title=f"[bold green]{icons.icon_success()}{result.tool_name}[/bold green]",
                    subtitle=token_subtitle,
                    border_style="green",
                )
            )
        else:
            error_msg = result.result.error or "Unknown error"
            self._console.print(
                _rich_panel.Panel(
                    f"[red]{error_msg}[/red]",
                    title=f"[bold red]{icons.icon_failure()}{result.tool_name}[/bold red]",
                    subtitle=token_subtitle,
                    border_style="red",
                )
            )

    def show_error(self, error: str) -> None:
        """Display an error message."""
        self._console.print(f"[bold red]Error:[/bold red] {error}")

    def show_info(self, message: str) -> None:
        """Display an informational message."""
        self._console.print(f"[dim]{message}[/dim]")

    def start_streaming(self) -> None:
        """Start streaming mode - actual Live displays are created lazily."""
        self._streaming = True
        self._stream_content = ""
        # Don't create Live display yet - it will be created lazily
        # when content actually arrives (thinking or text)

    def end_streaming(self) -> None:
        """End live streaming display."""
        if self._live:
            # Stop the live display (transient=True clears it)
            self._live.stop()
            self._live = None

            # Print final panel if we have content
            # (Whitespace filtering is done in RendererCallbacks)
            if self._stream_content:
                self._console.print(
                    _rich_panel.Panel(
                        _rich_markdown.Markdown(self._stream_content),
                        title="[bold green]Assistant[/bold green]",
                        subtitle=self._token_footer() or None,
                        border_style="green",
                    )
                )

        self._streaming = False
        self._stream_content = ""

    def prompt_permission(
        self,
        tool_call: base.ToolCallDisplay,
        *,
        auto_approve: bool = False,
    ) -> bool:
        """Ask user for permission to execute a tool."""
        if auto_approve:
            return True

        # Tool call is already displayed by caller, just prompt
        return _rich_prompt.Confirm.ask(
            f"[yellow]Allow {tool_call.tool_name}?[/yellow]",
            console=self._console,
            default=False,
        )

    def finalize(self, result: dict[str, _typing.Any] | None = None) -> None:
        """Finalize output - show usage stats if available."""
        if result and "usage" in result:
            usage = result["usage"]
            self._console.print(
                f"\n[dim]Tokens: {usage.get('input_tokens', 0)} in / "
                f"{usage.get('output_tokens', 0)} out[/dim]"
            )

    def show_finish(
        self,
        status: str,
        summary: str,
        next_steps: str | None = None,
    ) -> None:
        """Display finish status when agent calls the Finish tool."""
        # Choose icon and color based on status
        status_styles = {
            "success": ("‚úÖ", "green", "bold green"),
            "partial": ("‚ö†Ô∏è", "yellow", "bold yellow"),
            "failed": ("‚ùå", "red", "bold red"),
            "blocked": ("üöß", "blue", "bold blue"),
        }
        icon, border_color, title_color = status_styles.get(
            status, ("‚ÑπÔ∏è", "white", "bold white")
        )

        # Build content
        content_lines = [f"[{title_color}]Status: {status}[/{title_color}]", ""]
        content_lines.append(f"[white]{summary}[/white]")

        if next_steps:
            content_lines.append("")
            content_lines.append(f"[dim]Next steps: {next_steps}[/dim]")

        self._console.print(
            _rich_panel.Panel(
                "\n".join(content_lines),
                title=f"{icon} Task Finished",
                border_style=border_color,
                expand=True,
            )
        )

